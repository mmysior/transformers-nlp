{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a7b2ae-87a3-429b-8e69-c89ddf1f9b0e",
   "metadata": {},
   "source": [
    "# Basic NLP tasks using Huggingface transformers ü§ó\n",
    "This notebook contains examples of NLP tasks like:  \n",
    "- text summarization\n",
    "- text classification\n",
    "- machine translation\n",
    "- question answering\n",
    "- named entity recognition  \n",
    "\n",
    "By the end of this notebook, you will clearly understand how to utilize Transformer models for NLP tasks, specifically sentiment analysis, using Python and the Transformers library. Whether you are a data scientist, a machine learning enthusiast, or simply curious about NLP, this notebook is designed to provide a practical and hands-on experience.\n",
    "\n",
    "## HuggingFace platform ü§ó\n",
    "\n",
    "Hugging Face is forefront of the latest Natural Language Processing (NLP) advancements. It has become synonymous with state-of-the-art machine learning models, especially in language understanding and generation. Renowned for its comprehensive, open-source library \"Transformers\", Hugging Face provides an easy-to-use platform that houses a wide range of pre-trained models such as BERT, GPT, T5, and DistilBERT.\n",
    "\n",
    "These models, built using deep learning techniques, can perform various complex NLP tasks, including but not limited to sentiment analysis, text summarization, translation, and question-answering. Hugging Face's platform facilitates rapid deployment and experimentation, making it a favorite among researchers, data scientists, and developers in academic settings.\n",
    "\n",
    "First, the notebook presents a sentence classification application. Then, additional tasks typical for NLP are presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b2bc5-d290-4cae-9995-71efde65c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb9695-05ab-4d29-8794-ec25eefe01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9708cea-5314-485e-ac1a-a659485c9841",
   "metadata": {},
   "source": [
    "## Sentiment analysis example üßê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291bef5e-9592-4377-a156-a1a990fb6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model from Huggingface Hub\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26836411-04ae-4f5d-ad0b-19b8ae8c555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "\n",
    "model_classification = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer_classification = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", \n",
    "                      model=model_classification,\n",
    "                      tokenizer=tokenizer_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a74b0-9bd3-4756-8e65-9fb89866dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    (\"This product is amazing! Highly recommended.\", \"POSITIVE\"),\n",
    "    (\"Absolutely terrible service, very disappointed.\", \"NEGATIVE\"),\n",
    "    (\"Quite good, but could be better.\", \"POSITIVE\"),\n",
    "    (\"I love this! Definitely buying again.\", \"POSITIVE\"),\n",
    "    (\"Not what I expected, quite underwhelming.\", \"NEGATIVE\"),\n",
    "    (\"This is the best purchase I've ever made.\", \"POSITIVE\"),\n",
    "    (\"Complete waste of money, do not buy this.\", \"NEGATIVE\"),\n",
    "    (\"An average product, nothing special.\", \"NEGATIVE\"),\n",
    "    (\"Exceeded my expectations, wonderful quality!\", \"POSITIVE\"),\n",
    "    (\"The service was bad, and the product is faulty.\", \"NEGATIVE\"),\n",
    "    (\"I'm so happy with this, great job!\", \"POSITIVE\"),\n",
    "    (\"It's okay, but I've seen better.\", \"NEGATIVE\"),\n",
    "    (\"Worst experience ever, will not be returning.\", \"NEGATIVE\"),\n",
    "    (\"This is exactly what I needed, thank you!\", \"POSITIVE\"),\n",
    "    (\"Mediocre, not worth the hype.\", \"NEGATIVE\"),\n",
    "    (\"Impressed with the fast delivery and quality.\", \"POSITIVE\"),\n",
    "    (\"Terrible quality, broke after one use.\", \"NEGATIVE\"),\n",
    "    (\"Good for the price, but has some issues.\", \"POSITIVE\"),\n",
    "    (\"I'm very satisfied with my purchase.\", \"POSITIVE\"),\n",
    "    (\"Disappointing product, not as described.\", \"NEGATIVE\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed94695-1a24-48a5-9a1b-2cf87f2befc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {\"review\": [],\n",
    "               \"actual_sent\": [], \n",
    "               \"predicted_sent\": []}\n",
    "for review, actual_sentiment in reviews:\n",
    "    predicted_sentiment = classifier(review)[0]['label']\n",
    "    output_dict[\"review\"].append(review)    \n",
    "    output_dict[\"actual_sent\"].append(actual_sentiment)\n",
    "    output_dict[\"predicted_sent\"].append(predicted_sentiment)\n",
    "output_df = pd.DataFrame(output_dict)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2ae1d-f9a6-41b8-8b6c-d03a24d2f714",
   "metadata": {},
   "source": [
    "### Text classification on existing dataset\n",
    "\n",
    "Let's load an existing dataset from HiggingFace Hub. The dataset used in the example was obtained from  `https://huggingface.co/datasets/glue`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90e3b6-8375-436d-b3db-6ed42c2d2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"glue\", \"sst2\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02761dd0-8386-4737-b744-d244ff9aa0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"glue\", \"sst2\", split='train')\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa337c-893e-4e40-81fb-4baed62f1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "\n",
    "subset = dataset_df.sample(n_samples, random_state=53)\n",
    "X = list(subset['sentence'])\n",
    "y = list(subset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3cf154-eb39-4112-bfe2-d67ffecfa8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [classifier(rev)[0]['label'] for rev in X]\n",
    "yhat = [1 if res == \"POSITIVE\" else 0 for res in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b7956-a8be-40b0-956d-23b152bf77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.abs(np.array(y) - np.array(yhat))\n",
    "accuracy = 1 - (np.sum(diff)) / len(diff)\n",
    "print(f'Accuracy on the set: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb02375-8b57-4564-8189-3bb561fadcff",
   "metadata": {},
   "source": [
    "## Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5973ae-4871-4844-b36b-9a8912b6f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts\n",
    "news_article = \"\"\"\n",
    "Climate change is accelerating, with carbon dioxide levels rising and global temperatures increasing at an alarming rate. \n",
    "The impact is seen worldwide, with more frequent and severe weather events like hurricanes, droughts, and wildfires. \n",
    "Scientists are urging immediate action to reduce greenhouse gas emissions to mitigate these effects.\n",
    "\"\"\"\n",
    "\n",
    "scientific_abstract = \"\"\"\n",
    "In this study, we explore the application of convolutional neural networks (CNNs) in classifying medical imaging. \n",
    "Our dataset comprises 10,000 MRI scans of various brain diseases. We trained our CNN model using this dataset and \n",
    "achieved a 95% accuracy in differentiating between malignant and benign tumors, outperforming traditional methods.\n",
    "\"\"\"\n",
    "\n",
    "story_excerpt = \"\"\"\n",
    "Once upon a time in a faraway land, there was a kingdom of extraordinary beauty. The kingdom was known for its \n",
    "enchanting forests and a majestic castle where the beloved royal family lived. Despite its beauty, the kingdom faced \n",
    "troubles from a fearsome dragon that threatened peace.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6f4e5-2141-4bf1-814a-2404b6a225b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing each text\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "articles = [news_article, scientific_abstract, story_excerpt]\n",
    "for i, text in enumerate(articles):\n",
    "    summary = summarizer(text, max_length=30, min_length=10, do_sample=False)\n",
    "    print(f'Summary of the article no {i+1}:\\n{summary[0][\"summary_text\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402cff1-4d1f-4e95-8aad-78a89dc75d98",
   "metadata": {},
   "source": [
    "## Text translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556185f-b7e0-477b-acc1-f1190039b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation\", model=\"sdadas/mt5-base-translator-en-pl\")\n",
    "enpl_translation = translator(\"We are now learning how to use natural Language Processing in Python\")\n",
    "print(enpl_translation[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f776d1a-0c7d-477b-9e68-6a2d31e3a9e2",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1ca04-ffb8-4744-bab8-b3e3a57fde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = pipeline(model=\"deepset/roberta-base-squad2\")\n",
    "oracle(question=\"Where do I live?\", context=\"My name is Wolfgang and I live in Wroclaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d26dd-5b1e-41fb-a801-0b0bef8fbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Pythagoras was an ancient Ionian Greek philosopher and the eponymous founder of Pythagoreanism. His political and \n",
    "religious teachings were well known in Magna Graecia and influenced the philosophies of Plato, Aristotle, and, \n",
    "through them, Western philosophy. Knowledge of his life is clouded by legend, but he appears to have been the son of \n",
    "Mnesarchus, a gem engraver on the island of Samos. Modern scholars disagree regarding Pythagoras's education and \n",
    "influences, but they do agree that, around 530 BC, he traveled to Croton, where he founded a school in which \n",
    "initiates were sworn to secrecy and lived a communal, ascetic lifestyle.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"Who was Pythagoras?\",\n",
    "    \"What did Pythagoras influence?\",\n",
    "    \"Where did Pythagoras found his school?\"\n",
    "]\n",
    "\n",
    "# Answering each question\n",
    "for question in questions:\n",
    "    result = oracle(question=question, context=context)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {result['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a9e76-db98-4417-abba-1fd1c961daa5",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80747e8c-db4d-4041-a1a8-42537883962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Sample text\n",
    "text = \"Google was founded by Larry Page and Sergey Brin while they were students at Stanford University.\"\n",
    "\n",
    "# Performing NER\n",
    "ner_results = ner_pipeline(text)\n",
    "for entity in ner_results:\n",
    "    print(f\"Entity: {entity['word']}, Type: {entity['entity_group']}, Score: {entity['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994e3d1-5b4c-4f49-8a98-f49ec3a7daf9",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba4ca9-c982-4e50-9475-63c01121e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "capital = generator('The most popular programming language is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45872b50-0294-446d-8a31-d12062e9c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(capital[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb7012-0f5c-44be-a7fa-91f515721680",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682055b5-08b3-4306-a08a-8596d75f76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the text generation pipeline\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Style-specific prompts\n",
    "prompts = {\n",
    "    \"Shakespearean\": \"To be or not to be, that is the question:\",\n",
    "    \"News Report\": \"Today in New York City, a major event took place where\",\n",
    "    \"Science Fiction\": \"In a distant future, humanity has colonized Mars and\"\n",
    "}\n",
    "\n",
    "# Generating and displaying responses\n",
    "for style, prompt in prompts.items():\n",
    "    result = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    print(f\"Style: {style}\")\n",
    "    print(f\"Generated Text: {result[0]['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb102bde-fc59-45ae-a1ad-b1031cde5ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning the response by slightly altering prompts\n",
    "original_prompt = \"What is the best way to learn programming?\"\n",
    "modified_prompts = [\n",
    "    original_prompt,\n",
    "    \"As a beginner, \" + original_prompt,\n",
    "    \"In a fun and engaging way, \" + original_prompt\n",
    "]\n",
    "\n",
    "# Generating responses\n",
    "for prompt in modified_prompts:\n",
    "    result = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Generated Text: {result[0]['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6265e-c18f-4bef-a841-f6e70bee4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre-specific prompts\n",
    "genres = {\n",
    "    \"Horror\": \"In a dark, abandoned house, there was a mysterious noise that\",\n",
    "    \"Comedy\": \"At the comedy club, the stand-up comedian started his act by saying:\",\n",
    "    \"Romantic\": \"In the beautiful city of Paris, two lovers met and\"\n",
    "}\n",
    "\n",
    "# Generating genre-specific texts\n",
    "for genre, prompt in genres.items():\n",
    "    result = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"Generated Text: {result[0]['generated_text']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-toolkit",
   "language": "python",
   "name": "nlp-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
